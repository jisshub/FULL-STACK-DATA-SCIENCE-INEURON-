{
 "cells":[
  {
   "cell_type":"markdown",
   "source":[
    "# Web Scraping With BeautifulSoup and Request"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"PIB7a80aw6sONe2WNXgVH2"
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "What is web scraping ?\n",
    "- Process of extracting informations from a webpage by using patterns in webpage."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"I8qpD7ZTs75YNUyw1blxfz"
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "**We will scrap from website https:\/\/coreyms.com\/**\n",
    "\n",
    "**Grab post titles, summaries, links to youtube videos from this webpage**\n",
    "\n",
    "**At Start we will scrap a simple html page to get idea about\n",
    "scraping.**\n",
    "\n",
    "to parse html file, we use **lxml parser**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"DXqp1JhoGew0490ceThbHx"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "with open('simple.html') as html_file:\n",
    "    soup = BeautifulSoup(html_file)\n",
    "print(soup.prettify())"
   ],
   "execution_count":3,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "<!DOCTYPE html>\n",
      "<html class=\"no-js\" lang=\"\">\n",
      " <head>\n",
      "  <title>\n",
      "   Test - A Sample Website\n",
      "  <\/title>\n",
      "  <meta charset=\"utf-8\"\/>\n",
      "  <link href=\"css\/normalize.css\" rel=\"stylesheet\"\/>\n",
      "  <link href=\"css\/main.css\" rel=\"stylesheet\"\/>\n",
      " <\/head>\n",
      " <body>\n",
      "  <h1 id=\"site_title\">\n",
      "   Test Website\n",
      "  <\/h1>\n",
      "  <hr\/>\n",
      "  <div class=\"article\">\n",
      "   <h2>\n",
      "    <a href=\"article_1.html\">\n",
      "     Article 1 Headline\n",
      "    <\/a>\n",
      "   <\/h2>\n",
      "   <p>\n",
      "    This is a summary of article 1\n",
      "   <\/p>\n",
      "  <\/div>\n",
      "  <hr\/>\n",
      "  <div class=\"article\">\n",
      "   <h2>\n",
      "    <a href=\"article_2.html\">\n",
      "     Article 2 Headline\n",
      "    <\/a>\n",
      "   <\/h2>\n",
      "   <p>\n",
      "    This is a summary of article 2\n",
      "   <\/p>\n",
      "  <\/div>\n",
      "  <hr\/>\n",
      "  <div class=\"footer\">\n",
      "   <p>\n",
      "    Footer Information\n",
      "   <\/p>\n",
      "  <\/div>\n",
      "  <script src=\"js\/vendor\/modernizr-3.5.0.min.js\">\n",
      "  <\/script>\n",
      "  <script src=\"js\/plugins.js\">\n",
      "  <\/script>\n",
      "  <script src=\"js\/main.js\">\n",
      "  <\/script>\n",
      " <\/body>\n",
      "<\/html>\n",
      "\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"osUFC9jWea6HcceitjCJW3"
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## using find() method to extract a specific tag"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"NCCU8FsnfkMXUeWYJztg86"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "match = soup.find('div', class_ = 'footer')\n",
    "print(match)\n",
    "# pass class_ attribute to get a div with class footer"
   ],
   "execution_count":5,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "<div class=\"footer\">\n",
      "<p>Footer Information<\/p>\n",
      "<\/div>\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"L9AKl6iKRsyDgMVXypaXDU"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "match = soup.find('h1', id=\"site_title\")\n",
    "print(match)"
   ],
   "execution_count":6,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "<h1 id=\"site_title\">Test Website<\/h1>\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"kcbGU8vruq6sb5xo1GonKK"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "\n",
    "# Get headline and summary of article\n",
    "article = soup.find('div',  class_=\"article\")\n",
    "headline = article.h2.a.text\n",
    "summary = article.p.text\n",
    "print(headline)\n",
    "print(summary)"
   ],
   "execution_count":10,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Article 1 Headline\n",
      "This is a summary of article 1\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"MepuyXr1COR1YMHejkJW9z"
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Using find_all() method \n",
    "- find_all() method returns a list of all matches"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"5YeAHgxl6K8crRKxaw4zTk"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "for article in soup.find_all('div', class_='article'):\n",
    "    headline = article.h2.a.text\n",
    "    summary = article.p.text\n",
    "    print(headline)\n",
    "    print(summary)"
   ],
   "execution_count":12,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Article 1 Headline\n",
      "This is a summary of article 1\n",
      "Article 2 Headline\n",
      "This is a summary of article 2\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"gZYnWwGr3hcB5NdBkmdetN"
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# Scrapping Real Website"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"1fvlXAYGT7D2BKEIqaOVGp"
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "https:\/\/coreyms.com\/**\n",
    "\n",
    "To get response from above webpage we have to sent a request to the same.\n",
    "\n",
    "For such purpose, we use **requests** library.\n",
    "\n",
    "- Pass **text** property to get text value of request.\n",
    "- parsethe data using **BeautifulSoup**\n",
    "- We need to extract heading, summary, video link from page.\n",
    "- Transform the video link to below format as well\n",
    "    - https:\/\/www.youtube.com\/watch?v=ng2o98k983k\n",
    "- Store those information in a csv file."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"QKoUwaVUK95Ts2bjb7zHYU"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import csv\n",
    "data_file = open('scrap_data.csv', 'w')\n",
    "csv_writer = csv.writer(data_file)\n",
    "csv_writer.writerow(['Heading', 'Summary', 'Youtube URL'])\n",
    "source = requests.get('http:\/\/coreyms.com').text\n",
    "# parse the page \n",
    "soup = BeautifulSoup(source)\n",
    "for article in soup.find_all('article'):\n",
    "    heading = article.header.h2.a.text\n",
    "    summary = article.find('div', class_=\"entry-content\").p.text\n",
    "    youtube_url = article.find('iframe', class_='youtube-player')['src']\n",
    "    youtube_url = youtube_url.split('?')[0]\n",
    "    youtube_url = re.sub('embed\/', 'watch?v=', youtube_url)\n",
    "    csv_writer.writerow([heading, summary, youtube_url])\n",
    "# close the csv file\n",
    "data_file.close()"
   ],
   "execution_count":74,
   "outputs":[
    {
     "ename":"TypeError",
     "evalue":"TypeError: 'NoneType' object is not subscriptable",
     "traceback":[
      "\u001b[0;31m---------------------------------------------------------------------------",
      "Traceback (most recent call last)",
      "    at line 14 in <module>",
      "TypeError: 'NoneType' object is not subscriptable"
     ],
     "output_type":"error"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"bqOg8uc3XBUx5uma6ebS7c"
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# Exercise Programs"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"t8G9LiUzRHyZVdQxXVHL3J"
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Scraping Numbers from HTML using BeautifulSoup In this assignment you will write a Python program similar to http:\/\/www.py4e.com\/code3\/urllink2.py. The program will use urllib to read the HTML from the data files below, and parse the data, extracting numbers and compute the sum of the numbers in the file.\n",
    "\n",
    "Actual data: http:\/\/py4e-data.dr-chuck.net\/comments_1331184.html"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"26USsMdwp5P45dfGfLshK4"
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Using beautifulsoup to fetch data"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"gq17km8QKJdPU2vQmtvE42"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "data_source = requests.get('http:\/\/py4e-data.dr-chuck.net\/comments_1331184.html').text\n",
    "soup = BeautifulSoup(data_source)\n",
    "def extract_compute():\n",
    "    return sum([int(number.text) for number in soup.find_all('span', class_='comments')])\n",
    "print(extract_compute())"
   ],
   "execution_count":19,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "2359\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"5MFCgJx7bH7vbMoNu5YHxm"
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Using urllib.request library to fetch data"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"EIgcernZRHNec9oC8YrJDM"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "with urllib.request.urlopen('http:\/\/py4e-data.dr-chuck.net\/comments_1331184.html') as html_res:\n",
    "    data_source = html_res.read()\n",
    "soup = BeautifulSoup(data_source)\n",
    "def extract_compute():\n",
    "    return sum([int(number.text) for number in soup.find_all('span', class_='comments')])\n",
    "print(extract_compute())"
   ],
   "execution_count":21,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "2359\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"Z4dZwJEVuCwwiCmIrBD6hZ"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"RIdVji8nxVe5YycSilIKfB"
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "version":1,
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    
   ]
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}